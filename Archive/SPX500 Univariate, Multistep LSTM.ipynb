{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate, Multistep LSTM Implementation\n",
    "\n",
    "An implementation of a univariate, multistep LSTM for the Close price of NYSE: ECL operating on daily resolution. The model uses 30 timesteps back to predict 30 timesteps forward. Data pre-processing has been completed in another notebook.\n",
    "\n",
    "## Table of Contents\n",
    "* Libraries\n",
    "* Load Data\n",
    "  * Split Data\n",
    "* Vanilla LSTM\n",
    "* LSTM Optimization\n",
    "* LSTM Walk Forward Validation\n",
    "* Validation Results\n",
    "  * Overall\n",
    "  * First Model\n",
    "  * Last Model\n",
    "* Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "#### Daily Resolution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5031, 16)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    keep_col = list(range(1,18))\n",
    "\n",
    "    df_day = pd.read_csv('Clean Data/ECL_Clean_Day.csv', \n",
    "                         infer_datetime_format=True,\n",
    "                         parse_dates=['Timestamp'], \n",
    "                         index_col=['Timestamp'],\n",
    "                         usecols = keep_col,\n",
    "                         date_parser=lambda col: pd.to_datetime(col, utc=True).tz_convert('America/New_York'))\n",
    "\n",
    "    print (df_day.shape)\n",
    "    \n",
    "#print (df_day.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data\n",
    "\n",
    "We'll use the past 10 years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 10 years of data from 2019 - 2010\n",
    "day_data = df_day[df_day.index >= '2010-01-01']\n",
    "\n",
    "#split 7 years train, 3 years test\n",
    "day_train = day_data[day_data.index <= '2017-01-01']\n",
    "day_test = day_data[day_data.index >= '2017-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice out 'Close' price from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = day_train['Close'] \n",
    "base_test = day_test['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Test and Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(base_test)\n",
    "plt.plot(base_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla LSTM\n",
    "\n",
    "Initialize a vanilla, stacked LSTM with two LSTM layers stacked and a single dense layer to provide the output.\n",
    "\n",
    "Following Ex. 9.4.1, Univariate Multistep Forecasting with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1703, 30) (1703, 30) (695, 30) (695, 30)\n"
     ]
    }
   ],
   "source": [
    "# Multistep Data Preparation\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 30, 30\n",
    "\n",
    "# split into samples\n",
    "X_train, y_train = split_sequence(base_train.values, n_steps_in, n_steps_out)\n",
    "X_test, y_test = split_sequence(base_test.values, n_steps_in, n_steps_out)\n",
    "\n",
    "# summarize the data\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 100)           40800     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                3030      \n",
      "=================================================================\n",
      "Total params: 124,230\n",
      "Trainable params: 124,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/jacobscottanthony/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1703 samples, validate on 695 samples\n",
      "Epoch 1/20\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 22481.2097 - val_loss: 390045.3626\n",
      "Epoch 2/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 129696.2955 - val_loss: 1306427.2428\n",
      "Epoch 3/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 103670.7970 - val_loss: 17642.1842\n",
      "Epoch 4/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 1970.2524 - val_loss: 2599.3957\n",
      "Epoch 5/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 597.3957 - val_loss: 773.4431\n",
      "Epoch 6/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 283.2528 - val_loss: 357.6429\n",
      "Epoch 7/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 249.1233 - val_loss: 515.8741\n",
      "Epoch 8/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 84.4275 - val_loss: 787.3829\n",
      "Epoch 9/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 50989.4012 - val_loss: 20955.9645\n",
      "Epoch 10/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 21234.0082 - val_loss: 12487.5413\n",
      "Epoch 11/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 986.5226 - val_loss: 189.2244\n",
      "Epoch 12/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 34.9006 - val_loss: 105.7572\n",
      "Epoch 13/20\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 28.2267 - val_loss: 105.3798\n",
      "Epoch 14/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 28.0281 - val_loss: 107.9549\n",
      "Epoch 15/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 28.0428 - val_loss: 112.1920\n",
      "Epoch 16/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 28.0055 - val_loss: 117.8965\n",
      "Epoch 17/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 27.9697 - val_loss: 122.0411\n",
      "Epoch 18/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 27.9760 - val_loss: 123.8721\n",
      "Epoch 19/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 28.0284 - val_loss: 124.6215\n",
      "Epoch 20/20\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 28.1100 - val_loss: 125.3589\n"
     ]
    }
   ],
   "source": [
    "#Load required Keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "#print (X_train.shape)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "#print (X_test.shape)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "opt = Adam(lr=.001)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "model.summary()\n",
    "print ('\\n')\n",
    "\n",
    "# fit model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, \n",
    "                    batch_size=30,\n",
    "                    verbose=1, \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the Training and Validation Loss\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Training Results\n",
    "* Seems to be fine\n",
    "* Looks OK\n",
    "* What else can I do?\n",
    "\n",
    "### Demonstrate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test[0]:, (30, 1)\n",
      "Shape of x_input: (1, 30, 1)\n",
      "Shape of yhat: (1, 30)\n"
     ]
    }
   ],
   "source": [
    "# Use X_test[0] as test\n",
    "x_input = X_test[0]\n",
    "print ('Shape of X_test[0]:,',X_test[0].shape)\n",
    "\n",
    "# Reshape X_test[0]\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "print ('Shape of x_input:', x_input.shape)\n",
    "\n",
    "# Make a prediction\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print ('Shape of yhat:', yhat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the input, output and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,31), X_test[0], label = 'X_test')\n",
    "plt.plot(range(31, 61), y_test[0], label = 'y_test')\n",
    "plt.plot(range(31, 61), yhat[0], label = 'yhat')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.710191497802736\n",
      "Mean Squared Error: 33.55018757500237\n"
     ]
    }
   ],
   "source": [
    "mae = metrics.mean_absolute_error(y_test[0], yhat[0])\n",
    "rmse = metrics.mean_squared_error(y_test[0], yhat[0])\n",
    "print ('Mean Absolute Error:', mae)\n",
    "print ('Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Results\n",
    "* Results\n",
    "* Results\n",
    "\n",
    "## LSTM Architecture Optimization\n",
    "* In order to arrive at an optimized architecture for the LSTM, I have used the ```talos``` library. This allows an extensive grid search to be setup and then automated. This has been conduced on a Google Cloud VM. The Jupyter Notebook used can be found here [here].\n",
    "<br>\n",
    "* The best architecture from this grid search is summarized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the LSTM Model from the Talos grid search in a function to be called in the loop below\n",
    "\n",
    "def LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(400, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(200, activation='relu'))\n",
    "    model.add(Dense(90))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 30, 400)           643200    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 200)               480800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 90)                18090     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30)                2730      \n",
      "=================================================================\n",
      "Total params: 1,144,820\n",
      "Trainable params: 1,144,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_model()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discussion\n",
    "* Discussion\n",
    "* Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Forward Validation w/ re-fit\n",
    "\n",
    "Validate the model by waking it forward on the training set. Testing set size is kept stationary. Step size is 30 which is intended to mimic a realistic situation of re-training once per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccd928ab45e4e3fa9ac90f1f3ec2671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1703 samples, validate on 695 samples\n",
      "Epoch 1/100\n",
      "1703/1703 [==============================] - 16s 9ms/step - loss: 1009056.2281 - val_loss: 158730.7780\n",
      "Epoch 2/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 31798.2277 - val_loss: 8420.4639\n",
      "Epoch 3/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 1676.5408 - val_loss: 694.4623\n",
      "Epoch 4/100\n",
      "1703/1703 [==============================] - 17s 10ms/step - loss: 780.4796 - val_loss: 370.9977\n",
      "Epoch 5/100\n",
      "1703/1703 [==============================] - 16s 9ms/step - loss: 743.9853 - val_loss: 396.5112\n",
      "Epoch 6/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 564.0098 - val_loss: 380.3342\n",
      "Epoch 7/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 516.4172 - val_loss: 337.4849\n",
      "Epoch 8/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 511.8370 - val_loss: 333.2958\n",
      "Epoch 9/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 496.9721 - val_loss: 283.5672\n",
      "Epoch 10/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 492.3406 - val_loss: 314.0710\n",
      "Epoch 11/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 487.5157 - val_loss: 350.6800\n",
      "Epoch 12/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 475.0386 - val_loss: 343.2838\n",
      "Epoch 13/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 471.8261 - val_loss: 343.7411\n",
      "Epoch 14/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 477.7119 - val_loss: 285.4442\n",
      "Epoch 15/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 474.1491 - val_loss: 330.3012\n",
      "Epoch 16/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 466.4605 - val_loss: 274.2537\n",
      "Epoch 17/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 441.4057 - val_loss: 280.8843\n",
      "Epoch 18/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 462.0144 - val_loss: 241.6681\n",
      "Epoch 19/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 463.9096 - val_loss: 248.8681\n",
      "Epoch 20/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 450.1794 - val_loss: 261.7499\n",
      "Epoch 21/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 444.9682 - val_loss: 293.1599\n",
      "Epoch 22/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 435.4983 - val_loss: 277.7297\n",
      "Epoch 23/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 443.4619 - val_loss: 255.3439\n",
      "Epoch 24/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 443.7705 - val_loss: 272.4571\n",
      "Epoch 25/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 420.2915 - val_loss: 303.7571\n",
      "Epoch 26/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 414.2889 - val_loss: 224.0752\n",
      "Epoch 27/100\n",
      "1703/1703 [==============================] - 16s 9ms/step - loss: 407.5115 - val_loss: 260.2279\n",
      "Epoch 28/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 416.6683 - val_loss: 234.9355\n",
      "Epoch 29/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 409.2056 - val_loss: 274.2928\n",
      "Epoch 30/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 399.6713 - val_loss: 242.2519\n",
      "Epoch 31/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 401.8747 - val_loss: 350.0946\n",
      "Epoch 32/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 396.4228 - val_loss: 282.9284\n",
      "Epoch 33/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 394.0359 - val_loss: 238.0439\n",
      "Epoch 34/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 396.0106 - val_loss: 262.9382\n",
      "Epoch 35/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 397.6058 - val_loss: 201.4418\n",
      "Epoch 36/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 385.3209 - val_loss: 249.3787\n",
      "Epoch 37/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 371.8393 - val_loss: 242.8252\n",
      "Epoch 38/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 379.3381 - val_loss: 272.4785\n",
      "Epoch 39/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 352.3918 - val_loss: 285.6385\n",
      "Epoch 40/100\n",
      "1703/1703 [==============================] - 16s 9ms/step - loss: 349.0665 - val_loss: 306.6293\n",
      "Epoch 41/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 364.6393 - val_loss: 289.8524\n",
      "Epoch 42/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 365.3300 - val_loss: 198.5177\n",
      "Epoch 43/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 359.9221 - val_loss: 266.5705\n",
      "Epoch 44/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 347.6256 - val_loss: 274.3190\n",
      "Epoch 45/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 351.3676 - val_loss: 163.9934\n",
      "Epoch 46/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 342.5780 - val_loss: 241.1699\n",
      "Epoch 47/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 329.6689 - val_loss: 293.5524\n",
      "Epoch 48/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 332.2486 - val_loss: 261.3262\n",
      "Epoch 49/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 329.3808 - val_loss: 280.2914\n",
      "Epoch 50/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 325.1314 - val_loss: 204.5815\n",
      "Epoch 51/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 323.1208 - val_loss: 221.2043\n",
      "Epoch 52/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 326.7210 - val_loss: 237.1926\n",
      "Epoch 53/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 313.0894 - val_loss: 258.5488\n",
      "Epoch 54/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 313.9385 - val_loss: 277.3325\n",
      "Epoch 55/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 300.9939 - val_loss: 228.3884\n",
      "Epoch 56/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 310.5749 - val_loss: 230.9274\n",
      "Epoch 57/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 303.8655 - val_loss: 258.3519\n",
      "Epoch 58/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 301.2352 - val_loss: 241.2998\n",
      "Epoch 59/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 293.8373 - val_loss: 305.5662\n",
      "Epoch 60/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 295.7189 - val_loss: 240.2116\n",
      "Epoch 61/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 285.7753 - val_loss: 235.8130\n",
      "Epoch 62/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 290.8341 - val_loss: 258.5272\n",
      "Epoch 63/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 280.1064 - val_loss: 254.7490\n",
      "Epoch 64/100\n",
      "1703/1703 [==============================] - 14s 8ms/step - loss: 274.2171 - val_loss: 232.7937\n",
      "Epoch 65/100\n",
      "1703/1703 [==============================] - 15s 9ms/step - loss: 274.9023 - val_loss: 240.1770\n",
      "Step: 1\n",
      "MAE: 11.639185516728018\n",
      "RMSE: 240.17698309879265\n",
      "\n",
      "\n",
      "Train on 1733 samples, validate on 695 samples\n",
      "Epoch 1/100\n",
      "1733/1733 [==============================] - 15s 9ms/step - loss: 7698133.4990 - val_loss: 9185436.1367\n",
      "Epoch 2/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 395219.2080 - val_loss: 57114.7497\n",
      "Epoch 3/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 32473.9903 - val_loss: 29565.8665\n",
      "Epoch 4/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 80627325.9786 - val_loss: 260453.0366\n",
      "Epoch 5/100\n",
      "1733/1733 [==============================] - 15s 8ms/step - loss: 27627.6767 - val_loss: 24516.6067\n",
      "Epoch 6/100\n",
      "1733/1733 [==============================] - 15s 8ms/step - loss: 8137.9107 - val_loss: 24453.8088\n",
      "Epoch 7/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 8099.9537 - val_loss: 24379.4388\n",
      "Epoch 8/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 8094.9914 - val_loss: 24372.3279\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1733/1733 [==============================] - 14s 8ms/step - loss: 8091.9398 - val_loss: 24364.6739\n",
      "Epoch 10/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 8088.4556 - val_loss: 24354.9305\n",
      "Epoch 11/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 95957349.8359 - val_loss: 24328.3184\n",
      "Epoch 12/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 5401191.9652 - val_loss: 7537147.1942\n",
      "Epoch 13/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 20628783.5072 - val_loss: 3441688.2554\n",
      "Epoch 14/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 1309828.6683 - val_loss: 179184.0762\n",
      "Epoch 15/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 20762.2804 - val_loss: 9590.4125\n",
      "Epoch 16/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 1680.1073 - val_loss: 1208.6194\n",
      "Epoch 17/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 874.1649 - val_loss: 782.3240\n",
      "Epoch 18/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 717.8927 - val_loss: 559.7985\n",
      "Epoch 19/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 665.9301 - val_loss: 317.9539\n",
      "Epoch 20/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 598.6160 - val_loss: 314.8576\n",
      "Epoch 21/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 564.7767 - val_loss: 235.8619\n",
      "Epoch 22/100\n",
      "1733/1733 [==============================] - 15s 8ms/step - loss: 551.9097 - val_loss: 254.1124\n",
      "Epoch 23/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 535.7881 - val_loss: 256.2791\n",
      "Epoch 24/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 508.2478 - val_loss: 269.0378\n",
      "Epoch 25/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 498.7537 - val_loss: 244.3530\n",
      "Epoch 26/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 500.3892 - val_loss: 246.0311\n",
      "Epoch 27/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 480.1452 - val_loss: 240.7156\n",
      "Epoch 28/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 471.3926 - val_loss: 235.6391\n",
      "Epoch 29/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 472.7596 - val_loss: 199.5075\n",
      "Epoch 30/100\n",
      "1733/1733 [==============================] - 15s 9ms/step - loss: 464.0743 - val_loss: 229.9487\n",
      "Epoch 31/100\n",
      "1733/1733 [==============================] - 18s 10ms/step - loss: 461.1179 - val_loss: 226.7960\n",
      "Epoch 32/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 448.3090 - val_loss: 261.4645\n",
      "Epoch 33/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 451.1486 - val_loss: 242.7109\n",
      "Epoch 34/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 438.8908 - val_loss: 234.1324\n",
      "Epoch 35/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 443.5187 - val_loss: 241.0602\n",
      "Epoch 36/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 432.8266 - val_loss: 242.3191\n",
      "Epoch 37/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 435.8676 - val_loss: 196.2196\n",
      "Epoch 38/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 438.0108 - val_loss: 235.4592\n",
      "Epoch 39/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 437.5688 - val_loss: 201.8299\n",
      "Epoch 40/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 427.6167 - val_loss: 187.4266\n",
      "Epoch 41/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 425.1982 - val_loss: 218.4393\n",
      "Epoch 42/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 440.9329 - val_loss: 174.4420\n",
      "Epoch 43/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 441.5125 - val_loss: 238.8181\n",
      "Epoch 44/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 435.3326 - val_loss: 174.5660\n",
      "Epoch 45/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 441.1353 - val_loss: 229.6215\n",
      "Epoch 46/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 431.0395 - val_loss: 251.0556\n",
      "Epoch 47/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 423.8931 - val_loss: 182.9368\n",
      "Epoch 48/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 426.8915 - val_loss: 240.5033\n",
      "Epoch 49/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 428.4199 - val_loss: 196.7077\n",
      "Epoch 50/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 424.1430 - val_loss: 225.6677\n",
      "Epoch 51/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 423.5280 - val_loss: 237.9342\n",
      "Epoch 52/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 421.1349 - val_loss: 223.9960\n",
      "Epoch 53/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 435.3125 - val_loss: 198.5588\n",
      "Epoch 54/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 422.4231 - val_loss: 232.3151\n",
      "Epoch 55/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 429.6348 - val_loss: 234.6921\n",
      "Epoch 56/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 431.9976 - val_loss: 224.4214\n",
      "Epoch 57/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 426.3891 - val_loss: 238.6670\n",
      "Epoch 58/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 437.5998 - val_loss: 240.0198\n",
      "Epoch 59/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 428.4021 - val_loss: 266.4295\n",
      "Epoch 60/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 429.8570 - val_loss: 253.2640\n",
      "Epoch 61/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 429.7653 - val_loss: 173.1053\n",
      "Epoch 62/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 432.6334 - val_loss: 215.3626\n",
      "Epoch 63/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 428.0793 - val_loss: 309.1755\n",
      "Epoch 64/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 433.1320 - val_loss: 199.7807\n",
      "Epoch 65/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 433.2360 - val_loss: 255.7048\n",
      "Epoch 66/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 423.7980 - val_loss: 217.5712\n",
      "Epoch 67/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 432.2321 - val_loss: 295.1985\n",
      "Epoch 68/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 437.3120 - val_loss: 205.2795\n",
      "Epoch 69/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 445.5962 - val_loss: 458.5540\n",
      "Epoch 70/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 434.4264 - val_loss: 303.4744\n",
      "Epoch 71/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 420.3117 - val_loss: 164.8551\n",
      "Epoch 72/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 447.5013 - val_loss: 174.3900\n",
      "Epoch 73/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 444.3104 - val_loss: 168.5522\n",
      "Epoch 74/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 436.7730 - val_loss: 215.3433\n",
      "Epoch 75/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 435.9754 - val_loss: 250.7522\n",
      "Epoch 76/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 426.4856 - val_loss: 248.4540\n",
      "Epoch 77/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 429.3386 - val_loss: 213.0877\n",
      "Epoch 78/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 427.7808 - val_loss: 427.6549\n",
      "Epoch 79/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 423.7995 - val_loss: 414.2559\n",
      "Epoch 80/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 433.2583 - val_loss: 375.6568\n",
      "Epoch 81/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 426.5045 - val_loss: 488.8869\n",
      "Epoch 82/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 424.5344 - val_loss: 314.3219\n",
      "Epoch 83/100\n",
      "1733/1733 [==============================] - 14s 8ms/step - loss: 438.3950 - val_loss: 534.2348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 426.5427 - val_loss: 322.4435\n",
      "Epoch 85/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 431.2509 - val_loss: 323.7580\n",
      "Epoch 86/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 418.3933 - val_loss: 455.4491\n",
      "Epoch 87/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 425.0042 - val_loss: 294.0694\n",
      "Epoch 88/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 431.9559 - val_loss: 309.7224\n",
      "Epoch 89/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 438.9997 - val_loss: 426.3728\n",
      "Epoch 90/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 422.7306 - val_loss: 367.7093\n",
      "Epoch 91/100\n",
      "1733/1733 [==============================] - 13s 8ms/step - loss: 437.8359 - val_loss: 290.3518\n",
      "Step: 2\n",
      "MAE: 13.848314595423851\n",
      "RMSE: 290.35170887143323\n",
      "\n",
      "\n",
      "Train on 1763 samples, validate on 695 samples\n",
      "Epoch 1/100\n",
      "1763/1763 [==============================] - 15s 8ms/step - loss: 83960.2052 - val_loss: 196648.8076\n",
      "Epoch 2/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 13662.2962 - val_loss: 13472.5247\n",
      "Epoch 3/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 1438.7965 - val_loss: 539.1071\n",
      "Epoch 4/100\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 540.5259 - val_loss: 179.7147\n",
      "Epoch 5/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 452.8311 - val_loss: 157.0890\n",
      "Epoch 6/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 411.2942 - val_loss: 124.3411\n",
      "Epoch 7/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 377.2355 - val_loss: 105.5269\n",
      "Epoch 8/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 359.3338 - val_loss: 118.4674\n",
      "Epoch 9/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 2929.0598 - val_loss: 573.3525\n",
      "Epoch 10/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 464.7443 - val_loss: 273.9645\n",
      "Epoch 11/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 345.6661 - val_loss: 156.3285\n",
      "Epoch 12/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 307.5460 - val_loss: 107.5152\n",
      "Epoch 13/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 288.2327 - val_loss: 83.3325\n",
      "Epoch 14/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 274.4438 - val_loss: 100.9017\n",
      "Epoch 15/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 269.9543 - val_loss: 89.8079\n",
      "Epoch 16/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 256.1666 - val_loss: 127.9348\n",
      "Epoch 17/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 253.7435 - val_loss: 109.8251\n",
      "Epoch 18/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 248.4659 - val_loss: 129.0759\n",
      "Epoch 19/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 235.5619 - val_loss: 153.0718\n",
      "Epoch 20/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 242.5684 - val_loss: 112.2737\n",
      "Epoch 21/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 226.2590 - val_loss: 142.8315\n",
      "Epoch 22/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 214.5029 - val_loss: 143.3124\n",
      "Epoch 23/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 217.1074 - val_loss: 167.7823\n",
      "Epoch 24/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 213.4827 - val_loss: 180.2471\n",
      "Epoch 25/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 203.9067 - val_loss: 157.6194\n",
      "Epoch 26/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 208.7061 - val_loss: 246.2745\n",
      "Epoch 27/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 198.9497 - val_loss: 206.7925\n",
      "Epoch 28/100\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 200.6971 - val_loss: 148.4570\n",
      "Epoch 29/100\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 199.5041 - val_loss: 251.3076\n",
      "Epoch 30/100\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 191.8761 - val_loss: 156.7890\n",
      "Epoch 31/100\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 185.7096 - val_loss: 229.2980\n",
      "Epoch 32/100\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 185.3116 - val_loss: 193.5256\n",
      "Epoch 33/100\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 177.0138 - val_loss: 202.0456\n",
      "Step: 3\n",
      "MAE: 11.63953110266084\n",
      "RMSE: 202.04561182024864\n",
      "\n",
      "\n",
      "Train on 1793 samples, validate on 695 samples\n",
      "Epoch 1/100\n",
      "1793/1793 [==============================] - 15s 9ms/step - loss: 1331.2346 - val_loss: 495.5006\n",
      "Epoch 2/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 351.5501 - val_loss: 212.6542\n",
      "Epoch 3/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 254.2482 - val_loss: 141.2873\n",
      "Epoch 4/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 211.6613 - val_loss: 206.9953\n",
      "Epoch 5/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 158.7610 - val_loss: 320.9163\n",
      "Epoch 6/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 144.5812 - val_loss: 251.7122\n",
      "Epoch 7/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 128.0856 - val_loss: 359.3617\n",
      "Epoch 8/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 117.4286 - val_loss: 563.7019\n",
      "Epoch 9/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 116.3409 - val_loss: 175.7923\n",
      "Epoch 10/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 107.0505 - val_loss: 191.8251\n",
      "Epoch 11/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 101.1100 - val_loss: 255.2203\n",
      "Epoch 12/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 103.9235 - val_loss: 227.9091\n",
      "Epoch 13/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 120.6750 - val_loss: 246.3960\n",
      "Epoch 14/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 98.6270 - val_loss: 229.1509\n",
      "Epoch 15/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 128.0867 - val_loss: 280.9960\n",
      "Epoch 16/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 501.2958 - val_loss: 178.1696\n",
      "Epoch 17/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 130.0973 - val_loss: 67.5611\n",
      "Epoch 18/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 107.0329 - val_loss: 67.2832\n",
      "Epoch 19/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 87.1115 - val_loss: 58.4628\n",
      "Epoch 20/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 90.8462 - val_loss: 66.4458\n",
      "Epoch 21/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 76.0130 - val_loss: 68.0178\n",
      "Epoch 22/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 70.8780 - val_loss: 74.1786\n",
      "Epoch 23/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 73.3159 - val_loss: 70.0643\n",
      "Epoch 24/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 65.6453 - val_loss: 103.2689\n",
      "Epoch 25/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 63.5761 - val_loss: 77.4333\n",
      "Epoch 26/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 60.2224 - val_loss: 74.8753\n",
      "Epoch 27/100\n",
      "1793/1793 [==============================] - 18s 10ms/step - loss: 62.2464 - val_loss: 88.8632\n",
      "Epoch 28/100\n",
      "1793/1793 [==============================] - 16s 9ms/step - loss: 61.8034 - val_loss: 97.0082\n",
      "Epoch 29/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 57.2121 - val_loss: 123.8730\n",
      "Epoch 30/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 56.0145 - val_loss: 85.5601\n",
      "Epoch 31/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 59.2470 - val_loss: 108.2439\n",
      "Epoch 32/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 56.6213 - val_loss: 124.3338\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1793/1793 [==============================] - 14s 8ms/step - loss: 55.2018 - val_loss: 104.3980\n",
      "Epoch 34/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 53.2748 - val_loss: 100.2079\n",
      "Epoch 35/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 54.1652 - val_loss: 99.6554\n",
      "Epoch 36/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 54.7375 - val_loss: 76.0960\n",
      "Epoch 37/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 53.2966 - val_loss: 71.6711\n",
      "Epoch 38/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 54.7470 - val_loss: 99.8805\n",
      "Epoch 39/100\n",
      "1793/1793 [==============================] - 14s 8ms/step - loss: 57.1604 - val_loss: 105.8774\n",
      "Step: 4\n",
      "MAE: 8.080282608926531\n",
      "RMSE: 105.87744273510889\n",
      "\n",
      "\n",
      "Train on 1823 samples, validate on 695 samples\n",
      "Epoch 1/100\n",
      "1823/1823 [==============================] - 16s 9ms/step - loss: 27651.9252 - val_loss: 2767.0888\n",
      "Epoch 2/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 1245.6369 - val_loss: 483.3943\n",
      "Epoch 3/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 503.7857 - val_loss: 228.9900\n",
      "Epoch 4/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 392.7878 - val_loss: 138.9196\n",
      "Epoch 5/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 356.2441 - val_loss: 172.9787\n",
      "Epoch 6/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 316.0318 - val_loss: 118.8168\n",
      "Epoch 7/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 273.1369 - val_loss: 107.9887\n",
      "Epoch 8/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 253.1899 - val_loss: 90.4005\n",
      "Epoch 9/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 237.3579 - val_loss: 89.1540\n",
      "Epoch 10/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 229.8569 - val_loss: 92.2460\n",
      "Epoch 11/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 217.0719 - val_loss: 83.1019\n",
      "Epoch 12/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 201.3358 - val_loss: 120.1666\n",
      "Epoch 13/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 194.6079 - val_loss: 119.0148\n",
      "Epoch 14/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 182.9604 - val_loss: 114.0868\n",
      "Epoch 15/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 185.1520 - val_loss: 146.5737\n",
      "Epoch 16/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 176.8285 - val_loss: 96.2018\n",
      "Epoch 17/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 174.6382 - val_loss: 117.4393\n",
      "Epoch 18/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 163.9373 - val_loss: 162.3440\n",
      "Epoch 19/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 160.9413 - val_loss: 154.3334\n",
      "Epoch 20/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 154.1333 - val_loss: 153.8085\n",
      "Epoch 21/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 153.8619 - val_loss: 187.9347\n",
      "Epoch 22/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 153.7798 - val_loss: 181.7106\n",
      "Epoch 23/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 148.2806 - val_loss: 178.8636\n",
      "Epoch 24/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 141.9757 - val_loss: 127.8510\n",
      "Epoch 25/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 143.8541 - val_loss: 85.9045\n",
      "Epoch 26/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 140.1458 - val_loss: 108.9027\n",
      "Epoch 27/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 132.7087 - val_loss: 101.4582\n",
      "Epoch 28/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 132.9699 - val_loss: 71.9355\n",
      "Epoch 29/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 123.4667 - val_loss: 87.4592\n",
      "Epoch 30/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 128.9096 - val_loss: 103.8067\n",
      "Epoch 31/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 125.3085 - val_loss: 200.8411\n",
      "Epoch 32/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 126.5786 - val_loss: 88.7407\n",
      "Epoch 33/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 120.1323 - val_loss: 159.3150\n",
      "Epoch 34/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 114.6638 - val_loss: 130.5261\n",
      "Epoch 35/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 117.9657 - val_loss: 75.4881\n",
      "Epoch 36/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 107.5703 - val_loss: 104.4008\n",
      "Epoch 37/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 105.5650 - val_loss: 105.2552\n",
      "Epoch 38/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 113.0154 - val_loss: 151.4264\n",
      "Epoch 39/100\n",
      "1823/1823 [==============================] - 14s 8ms/step - loss: 106.1259 - val_loss: 76.9430\n",
      "Epoch 40/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 113.8410 - val_loss: 79.8014\n",
      "Epoch 41/100\n",
      "1823/1823 [==============================] - 16s 9ms/step - loss: 114.5794 - val_loss: 76.6916\n",
      "Epoch 42/100\n",
      "1823/1823 [==============================] - 16s 9ms/step - loss: 108.1529 - val_loss: 68.4596\n",
      "Epoch 43/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 105.0202 - val_loss: 90.3398\n",
      "Epoch 44/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 101.0145 - val_loss: 95.4189\n",
      "Epoch 45/100\n",
      "1823/1823 [==============================] - 16s 9ms/step - loss: 97.3635 - val_loss: 78.3067\n",
      "Epoch 46/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 96.3073 - val_loss: 69.3366\n",
      "Epoch 47/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 95.6891 - val_loss: 110.9010\n",
      "Epoch 48/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 99.4590 - val_loss: 70.6562\n",
      "Epoch 49/100\n",
      "1823/1823 [==============================] - 15s 8ms/step - loss: 93.8238 - val_loss: 70.6121\n",
      "Epoch 50/100\n",
      " 960/1823 [==============>...............] - ETA: 6s - loss: 47.9551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d26a031e014a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                           shuffle=False)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#create the prediction counter for X_test loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Inputs for Walk-Forward with re-fit at each step\n",
    "X = day_data['Close'] \n",
    "n_train = len(base_train)\n",
    "n_records = len(base_train)+len(base_test)\n",
    "step = 30\n",
    "n_steps_in = 30\n",
    "n_steps_out = 30\n",
    "n_features = 1\n",
    "\n",
    "pred_dict = dict()\n",
    "errors = list()\n",
    "count = 0\n",
    "\n",
    "#Main Loop\n",
    "for i in tqdm.tqdm_notebook(np.arange(n_train, n_records, step)):\n",
    "    #split data\n",
    "    train, test = X[0:i], X[n_train:]\n",
    "    \n",
    "    #rearrange to supervised\n",
    "    X_train, y_train = split_sequence(train.values, n_steps_in, n_steps_out)\n",
    "    X_test, y_test = split_sequence(test.values, n_steps_in, n_steps_out)\n",
    "    \n",
    "    #reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "    \n",
    "    #create model\n",
    "    model = LSTM_model()\n",
    "    es = EarlyStopping(monitor='val_loss', mode='auto', patience=20)\n",
    "    \n",
    "    #fit the model\n",
    "    model_fit = model.fit(X_train, y_train, \n",
    "                          validation_data=(X_test, y_test), \n",
    "                          epochs=100, \n",
    "                          callbacks=[es],\n",
    "                          batch_size=30,\n",
    "                          verbose=1, \n",
    "                          shuffle=False)\n",
    "    \n",
    "    #create the prediction counter for X_test loop\n",
    "    time_count = 0\n",
    "    \n",
    "    #reset list for all the predictions\n",
    "    predictions = list()\n",
    "    \n",
    "    #reset dict to catch all the output dfs (res)\n",
    "    fore_dict = dict()\n",
    "    \n",
    "    #predict loop for each sample in X_test\n",
    "    for t in np.arange(0, len(X_test), 1):\n",
    "        x_input = X_test[t]\n",
    "        x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        predictions.append(yhat[0])\n",
    "        \n",
    "        #create output df and save into dict\n",
    "        res = pd.DataFrame(list(range(1,n_steps_out+1)), columns=['Day'])\n",
    "        res['Pred'] = yhat[0]\n",
    "        fore_dict[time_count] = res\n",
    "        time_count += 1\n",
    "    \n",
    "    pred_dict[count] = fore_dict\n",
    "    \n",
    "    #calculate error for all predictions (X_test)\n",
    "    mae = metrics.mean_absolute_error(y_test, predictions)\n",
    "    rmse = metrics.mean_squared_error(y_test, predictions)\n",
    "    err = [count+1, mae, rmse]\n",
    "    errors.append(err)\n",
    "    \n",
    "    #print update\n",
    "    print('Step:',count+1)\n",
    "    print('MAE:',mae)\n",
    "    print('RMSE:',rmse)\n",
    "    print('\\n')\n",
    "    \n",
    "    #increase counter\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results\n",
    "\n",
    "Plot the first and last models trained and compare their skill in terms of error. I'm using Mean Absolute Error and Mean Squared Error as the primary measures of model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Model Error\n",
    "\n",
    "When we calculate the errors, we're looking at each prediction at each timestep (724 samples x 30 timesteps prediction = 21,720 predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame.from_records(errors, columns=['Iteration', 'MAE', 'RMSE'])\n",
    "ax = error_df.plot(x='Iteration', y=['MAE', 'RMSE'], secondary_y=['RMSE'],\n",
    "             figsize=(15,4),\n",
    "             title='Error vs. Iteration',\n",
    "             colormap='jet')\n",
    "ax.set(ylabel='Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Observation\n",
    "* Observation\n",
    "* Observation\n",
    "\n",
    "Now, we'll zoom into two specific iterations (first and last) and explore their skill more deeply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the First and Last Model\n",
    "I'll create a single composite line from the model by sampling every 30th prediction (30 steps long) to create a single line. 26 steps x 30 timesteps prediction = 780 predictions\n",
    "#### First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first model (least training data) by sampling every 30th prediction (step) and appending to a list\n",
    "\n",
    "first_model = []\n",
    "for i in np.arange(0, len(X_test), step):\n",
    "    first_model.append(pred_dict[0][i]['Pred'])\n",
    "\n",
    "#unravel the array to plot the prediction over the actual\n",
    "first_pred = np.concatenate(first_model).ravel().tolist()\n",
    "\n",
    "#create a df with the timestamps and actual Close prices\n",
    "first_results = pd.DataFrame(base_test) #base_test[step:]\n",
    "\n",
    "#trim the length to match base_test as the last step isn't exactly 30 due to training set size\n",
    "first_results = first_results[:len(first_pred)]\n",
    "\n",
    "#add the prediction to the df\n",
    "first_results['Pred'] = first_pred\n",
    "\n",
    "#plot the df\n",
    "first_results.plot(figsize=(15,5), title='First Model Composite Prediction vs Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate Error for the Composite Line above\n",
    "\n",
    "first_total_MAE = metrics.mean_absolute_error(first_results['Close'], first_results['Pred'])\n",
    "first_total_RMSE = metrics.mean_squared_error(first_results['Close'], first_results['Pred'])\n",
    "\n",
    "print('Aggregate Error for the Composite Line')\n",
    "print('Mean Absolute Error:',first_total_MAE)\n",
    "print('Mean Squared Error:',first_total_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation for First Model\n",
    "\n",
    "first_corr = first_results.corr(method='pearson')['Close']['Pred']\n",
    "print ('Pearson Correlation for Close & Prediction:',first_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the First Models Error by Prediction Horizon ie. Error at t+1 through t+30\n",
    "\n",
    "first_error = pred_dict[0][0]\n",
    "\n",
    "#Sample the predictions\n",
    "for i in np.arange(1,len(X_test),step):\n",
    "    two = pd.DataFrame(pred_dict[0][i])\n",
    "    three = first_error.append(two, ignore_index=True)\n",
    "    first_error = three\n",
    "\n",
    "#Add the Actual Values\n",
    "first_error['Actual'] = base_test.values[0:len(first_error)]\n",
    "\n",
    "#intialize a list\n",
    "first_error_by_day = list()\n",
    "\n",
    "#calcualte the errors at each day by slicing the df\n",
    "for i in range(1,31):\n",
    "    df = first_error[first_error.Day == i]\n",
    "    err_MSE = metrics.mean_squared_error(df['Actual'],df['Pred'])\n",
    "    err_MAE = metrics.mean_absolute_error(df['Actual'],df['Pred'])\n",
    "    error = [i, err_MAE,err_MSE]\n",
    "    first_error_by_day.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Error vs Day\n",
    "\n",
    "first_error_day = pd.DataFrame.from_records(first_error_by_day, columns=['Day', 'MAE', 'RMSE'])\n",
    "first_ax = first_error_day.plot(x='Day', y=['MAE','RMSE'], \n",
    "                          secondary_y=['RMSE'],\n",
    "                         title = 'Errors vs Prediction Horizon')\n",
    "first_ax.set(ylabel='Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* One\n",
    "* Two\n",
    "* Three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the last model (most training data) by sampling every 30th prediction (step) and appending to a list\n",
    "\n",
    "last_model = []\n",
    "for i in np.arange(0,len(X_test),step):\n",
    "    last_model.append(pred_dict[max(pred_dict)][i]['Pred'])\n",
    "\n",
    "#unravel the array to plot the prediction over the actual\n",
    "last_pred = np.concatenate(last_model).ravel().tolist()\n",
    "\n",
    "#create a df with the timestamps and actual Close prices\n",
    "last_results = pd.DataFrame(base_test) #base_test[step:]\n",
    "\n",
    "#trim the length to match base_test as the last step isn't exactly 30 due to training set size\n",
    "last_results = last_results[:len(last_pred)]\n",
    "\n",
    "#add the prediction to the df\n",
    "last_results['Pred'] = last_pred\n",
    "\n",
    "#plot the df\n",
    "last_results.plot(figsize=(15,5), title='Last Model Composite Prediction vs Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate Error for the Composite Line above\n",
    "last_total_MAE = metrics.mean_absolute_error(last_results['Close'], last_results['Pred'])\n",
    "last_total_RMSE = metrics.mean_squared_error(last_results['Close'], last_results['Pred'])\n",
    "\n",
    "print('Aggregate Error for the Composite Line')\n",
    "print('Mean Absolute Error:',last_total_MAE)\n",
    "print('Mean Squared Error:',last_total_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_corr = last_results.corr(method='pearson')['Close']['Pred']\n",
    "print ('Pearson Correlation for Close & Prediction:',last_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample the last models predicitons to see the error by forecast day\n",
    "\n",
    "last_error = pred_dict[max(pred_dict)][0]\n",
    "\n",
    "#sample the predictions\n",
    "for i in np.arange(1,len(X_test),step):\n",
    "    two = pd.DataFrame(pred_dict[max(pred_dict)][i])\n",
    "    three = last_error.append(two, ignore_index=True)\n",
    "    last_error = three\n",
    "\n",
    "#add in the actual values\n",
    "last_error['Actual'] = base_test.values[0:len(last_error)]\n",
    "\n",
    "#create a list\n",
    "last_error_by_day = list()\n",
    "\n",
    "#calculate the error by day\n",
    "for i in range(1,31):\n",
    "    df = last_error[last_error.Day == i]\n",
    "    err_MSE = metrics.mean_squared_error(df['Actual'],df['Pred'])\n",
    "    err_MAE = metrics.mean_absolute_error(df['Actual'],df['Pred'])\n",
    "    error = [i, err_MAE,err_MSE]\n",
    "    last_error_by_day.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Error vs Day\n",
    "\n",
    "last_error_day = pd.DataFrame.from_records(last_error_by_day, columns=['Day', 'MAE', 'RMSE'])\n",
    "last_ax = last_error_day.plot(x='Day', y=['MAE','RMSE'], \n",
    "                          secondary_y=['RMSE'],\n",
    "                         title = 'Errors vs Prediction Horizon')\n",
    "last_ax.set(ylabel='Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm. Model performance is garbage, especially towards the end. I believe I need to retrain at each step.\n",
    "* Other thing\n",
    "* Other thing\n",
    "* Other things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This optimized architecture was able to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
